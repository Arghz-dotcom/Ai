{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prerequisites\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### **MNIST Dataset Setup**\n",
    "This section prepares the MNIST dataset for training and testing purposes.\n",
    "\n",
    "1. **`transforms.Compose`**:\n",
    "   - This is used to chain multiple transformations together, applied to the dataset.\n",
    "   - Transformations included:\n",
    "     - **`transforms.ToTensor()`**: Converts images (PIL or NumPy) into PyTorch tensors. The image pixel values are scaled to the range `[0, 1]` (normalized by dividing by 255).\n",
    "     - **`transforms.Normalize(mean, std)`**: Normalizes the tensor image by subtracting the mean and dividing by the standard deviation for each channel. \n",
    "       - Here, `mean=(0.5, 0.5, 0.5)` and `std=(0.5, 0.5, 0.5)` are used for normalization. This standardizes the pixel values to the range `[-1, 1]` because:\n",
    "         - Original range after `ToTensor()`: `[0, 1]`.\n",
    "         - Subtract 0.5 (mean): `[−0.5, 0.5]`.\n",
    "         - Divide by 0.5 (std): `[-1, 1]`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 100\n",
    "\n",
    "# MNIST Dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5, ), std=(0.5, ))])\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./mnist_data/', train=True, transform=transform, download=True)\n",
    "test_dataset = datasets.MNIST(root='./mnist_data/', train=False, transform=transform, download=False)\n",
    "\n",
    "# Data Loader (Input Pipeline)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=bs, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=bs, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Generator**\n",
    "The **Generator** is a neural network that creates synthetic data (e.g., fake images) starting from random noise. It learns to produce data that resembles the real dataset, fooling the discriminator.\n",
    "\n",
    "### **Code Explanation**\n",
    "- **`__init__` Method**:\n",
    "  - `g_input_dim`: Dimension of the random noise input (e.g., a vector of size 100).\n",
    "  - `g_output_dim`: Dimension of the output (e.g., size of the real data, such as 784 for MNIST images of 28x28 pixels).\n",
    "  - `self.fc1`, `self.fc2`, `self.fc3`, `self.fc4`: Fully connected (linear) layers. The network grows in feature size as it progresses:\n",
    "    - Input is transformed to 256 features in `fc1`.\n",
    "    - Doubled in `fc2`, then doubled again in `fc3`.\n",
    "    - Finally, it outputs the desired dimension (`g_output_dim`) in `fc4`.\n",
    "\n",
    "- **`forward` Method**:\n",
    "  - Takes in the random noise input `x`.\n",
    "  - Passes `x` through the fully connected layers with activation functions:\n",
    "    - **`F.leaky_relu`**: A variant of ReLU (Rectified Linear Unit) activation function with a small slope for negative values (`0.2` in this case). Helps gradients flow better during training, avoiding dead neurons.\n",
    "    - **`torch.tanh`**: Applied to the final layer to constrain the output between `-1` and `1`, which is often done for datasets normalized to this range (e.g., image datasets).\n",
    "\n",
    "### **Flow of Data in Generator**:\n",
    "1. Random noise `x` → `fc1` → Leaky ReLU.\n",
    "2. Output → `fc2` → Leaky ReLU.\n",
    "3. Output → `fc3` → Leaky ReLU.\n",
    "4. Output → `fc4` → Tanh → Final generated data.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Discriminator**\n",
    "The **Discriminator** is a neural network that classifies whether the input data is real (from the actual dataset) or fake (generated by the Generator). It outputs a single value (a probability).\n",
    "\n",
    "### **Code Explanation**\n",
    "- **`__init__` Method**:\n",
    "  - `d_input_dim`: Dimension of the input data (e.g., 784 for MNIST images).\n",
    "  - `self.fc1`, `self.fc2`, `self.fc3`, `self.fc4`: Fully connected layers. The network reduces feature size as it progresses:\n",
    "    - Input starts with 1024 features in `fc1`.\n",
    "    - Halved in `fc2`, then halved again in `fc3`.\n",
    "    - Outputs a single value (probability) in `fc4`.\n",
    "\n",
    "- **`forward` Method**:\n",
    "  - Takes input data `x` (either real or fake).\n",
    "  - Passes `x` through the layers with:\n",
    "    - **`F.leaky_relu`**: Activates the neurons similarly to the Generator.\n",
    "    - **`F.dropout`**: Randomly drops some neurons (30% dropout here) to prevent overfitting and improve generalization.\n",
    "    - **`torch.sigmoid`**: Applied to the final layer to squash the output into a probability between `0` and `1`.\n",
    "\n",
    "### **Flow of Data in Discriminator**:\n",
    "1. Input `x` → `fc1` → Leaky ReLU → Dropout.\n",
    "2. Output → `fc2` → Leaky ReLU → Dropout.\n",
    "3. Output → `fc3` → Leaky ReLU → Dropout.\n",
    "4. Output → `fc4` → Sigmoid → Final probability (real or fake).\n",
    "\n",
    "---\n",
    "\n",
    "## **How They Work Together**\n",
    "1. **Generator**:\n",
    "   - Takes random noise as input.\n",
    "   - Outputs fake data resembling the real dataset.\n",
    "\n",
    "2. **Discriminator**:\n",
    "   - Takes either real data or fake data (from the Generator) as input.\n",
    "   - Outputs a probability:\n",
    "     - Close to 1 for real data.\n",
    "     - Close to 0 for fake data.\n",
    "\n",
    "3. **Training**:\n",
    "   - The Generator tries to fool the Discriminator by generating more realistic data.\n",
    "   - The Discriminator tries to improve its ability to distinguish real data from fake data.\n",
    "   - This adversarial process helps the Generator improve over time, producing increasingly realistic data.\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Points**\n",
    "- **Generator** expands dimensions and learns to generate realistic data.\n",
    "- **Discriminator** reduces dimensions and learns to classify real vs. fake data.\n",
    "- The adversarial nature of GANs drives both networks to improve iteratively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, g_input_dim, g_output_dim):\n",
    "        super(Generator, self).__init__()       \n",
    "        self.fc1 = nn.Linear(g_input_dim, 256)\n",
    "        self.fc2 = nn.Linear(self.fc1.out_features, self.fc1.out_features*2)\n",
    "        self.fc3 = nn.Linear(self.fc2.out_features, self.fc2.out_features*2)\n",
    "        self.fc4 = nn.Linear(self.fc3.out_features, g_output_dim)\n",
    "    \n",
    "    # forward method\n",
    "    def forward(self, x): \n",
    "        x = F.leaky_relu(self.fc1(x), 0.2)\n",
    "        x = F.leaky_relu(self.fc2(x), 0.2)\n",
    "        x = F.leaky_relu(self.fc3(x), 0.2)\n",
    "        return torch.tanh(self.fc4(x))\n",
    "    \n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, d_input_dim):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.fc1 = nn.Linear(d_input_dim, 1024)\n",
    "        self.fc2 = nn.Linear(self.fc1.out_features, self.fc1.out_features//2)\n",
    "        self.fc3 = nn.Linear(self.fc2.out_features, self.fc2.out_features//2)\n",
    "        self.fc4 = nn.Linear(self.fc3.out_features, 1)\n",
    "    \n",
    "    # forward method\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.fc1(x), 0.2)\n",
    "        x = F.dropout(x, 0.3)\n",
    "        x = F.leaky_relu(self.fc2(x), 0.2)\n",
    "        x = F.dropout(x, 0.3)\n",
    "        x = F.leaky_relu(self.fc3(x), 0.2)\n",
    "        x = F.dropout(x, 0.3)\n",
    "        return torch.sigmoid(self.fc4(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Build Network**\n",
    "This section defines the **Generator (G)** and **Discriminator (D)** networks and sets them up for training.\n",
    "\n",
    "---\n",
    "\n",
    "### **Code Breakdown**\n",
    "\n",
    "#### **1.1 `z_dim`**\n",
    "```python\n",
    "z_dim = 100\n",
    "```\n",
    "- This defines the **dimension of the random noise vector** \\( z \\) that will be input to the Generator.\n",
    "- \\( z \\) is typically a latent space representation, where each vector is sampled randomly (e.g., from a normal or uniform distribution).\n",
    "- Commonly used values for `z_dim` are 64, 100, or 128.\n",
    "\n",
    "---\n",
    "\n",
    "#### **1.2 `mnist_dim`**\n",
    "```python\n",
    "mnist_dim = train_dataset.train_data.size(1) * train_dataset.train_data.size(2)\n",
    "```\n",
    "- This calculates the **dimensionality of the MNIST dataset images**.\n",
    "  - `train_dataset.train_data` is a tensor containing the training data (28x28 grayscale images for MNIST).\n",
    "  - `size(1)` gives the height of each image (28).\n",
    "  - `size(2)` gives the width of each image (28).\n",
    "  - Multiplying them gives the total number of pixels: \\( 28 \\times 28 = 784 \\).\n",
    "- `mnist_dim` is therefore set to 784, which is the input size for both:\n",
    "  - The **Discriminator**, which processes flattened 784-dimensional image data.\n",
    "  - The **Generator's output**, which generates fake data of the same dimension as real MNIST images.\n",
    "\n",
    "---\n",
    "\n",
    "#### **1.3 Create the Generator**\n",
    "```python\n",
    "G = Generator(g_input_dim=z_dim, g_output_dim=mnist_dim).to(device)\n",
    "```\n",
    "- **Generator Initialization**:\n",
    "  - `g_input_dim=z_dim`: The input dimension for the Generator is the random noise vector \\( z \\) of size 100.\n",
    "  - `g_output_dim=mnist_dim`: The Generator's output is the flattened MNIST image data of size 784.\n",
    "- **`.to(device)`**:\n",
    "  - Moves the Generator model to the specified device (`device`), which could be either CPU or GPU.\n",
    "  - This ensures all computations for the Generator are performed on the correct device.\n",
    "\n",
    "---\n",
    "\n",
    "#### **1.4 Create the Discriminator**\n",
    "```python\n",
    "D = Discriminator(mnist_dim).to(device)\n",
    "```\n",
    "- **Discriminator Initialization**:\n",
    "  - `d_input_dim=mnist_dim`: The Discriminator's input is the flattened MNIST image data (real or fake) of size 784.\n",
    "- **`.to(device)`**:\n",
    "  - Moves the Discriminator model to the specified device (CPU or GPU).\n",
    "\n",
    "---\n",
    "\n",
    "### **Summary**\n",
    "1. The **Generator**:\n",
    "   - Takes a 100-dimensional random noise vector as input.\n",
    "   - Outputs a 784-dimensional vector representing a fake MNIST image.\n",
    "\n",
    "2. The **Discriminator**:\n",
    "   - Takes a 784-dimensional vector as input (real MNIST image or fake image from the Generator).\n",
    "   - Outputs a probability indicating whether the input is real or fake.\n",
    "\n",
    "3. Both networks are transferred to the specified device (`device`) to ensure compatibility with hardware (e.g., GPU acceleration).\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Concepts**\n",
    "- **Why `z_dim`?**\n",
    "  - The random noise vector \\( z \\) serves as the input to the Generator. It is mapped to the data distribution of real images through the Generator's learned weights.\n",
    "  \n",
    "- **Why `mnist_dim`?**\n",
    "  - The MNIST images are flattened into 1D vectors of size 784 to be compatible with fully connected (linear) layers in both the Generator and Discriminator.\n",
    "\n",
    "- **Device Management**:\n",
    "  - Using `.to(device)` ensures that both the models and data tensors are placed on the same hardware (CPU or GPU). This is essential for efficient computation, especially during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\domin\\.conda\\envs\\pytorchgpu\\Lib\\site-packages\\torchvision\\datasets\\mnist.py:76: UserWarning: train_data has been renamed data\n",
      "  warnings.warn(\"train_data has been renamed data\")\n"
     ]
    }
   ],
   "source": [
    "# build network\n",
    "z_dim = 100\n",
    "mnist_dim = train_dataset.train_data.size(1) * train_dataset.train_data.size(2)\n",
    "\n",
    "G = Generator(g_input_dim = z_dim, g_output_dim = mnist_dim).to(device)\n",
    "D = Discriminator(mnist_dim).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (fc1): Linear(in_features=100, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=256, out_features=512, bias=True)\n",
       "  (fc3): Linear(in_features=512, out_features=1024, bias=True)\n",
       "  (fc4): Linear(in_features=1024, out_features=784, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (fc1): Linear(in_features=784, out_features=1024, bias=True)\n",
       "  (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  (fc3): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (fc4): Linear(in_features=256, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Loss Function**\n",
    "```python\n",
    "criterion = nn.BCELoss()\n",
    "```\n",
    "\n",
    "- **`nn.BCELoss()`**:\n",
    "  - **Binary Cross-Entropy Loss** is used to measure the difference between predicted probabilities and actual binary labels (real or fake).\n",
    "  - In the context of GANs:\n",
    "    - The Discriminator outputs a probability (via `torch.sigmoid`) for whether input data is real or fake.\n",
    "    - The Generator’s goal is to maximize the Discriminator's error, i.e., make its fake outputs appear real.\n",
    "  - Formula for Binary Cross-Entropy Loss:  \n",
    "    $\n",
    "    \\text{BCE Loss} = - \\frac{1}{N} \\sum_{i=1}^N [ y_i \\cdot \\log(p_i) + (1 - y_i) \\cdot \\log(1 - p_i) ]\n",
    "    $\n",
    "    - \\( y_i \\): True label (1 for real, 0 for fake).\n",
    "    - \\( p_i \\): Predicted probability.\n",
    "  - This loss helps:\n",
    "    - The **Discriminator** learn to classify real vs. fake images.\n",
    "    - The **Generator** improve so that its fake images are classified as real.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss\n",
    "criterion = nn.BCELoss() \n",
    "\n",
    "# optimizer\n",
    "lr = 0.0002 \n",
    "G_optimizer = optim.Adam(G.parameters(), lr = lr)\n",
    "D_optimizer = optim.Adam(D.parameters(), lr = lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s break down the function `D_train(x)` step by step. This function is responsible for **training the Discriminator (D)** in a GAN framework.\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Function Purpose**\n",
    "The goal of `D_train(x)` is to update the Discriminator so it can:\n",
    "1. Maximize the probability of correctly classifying **real images** as real.\n",
    "2. Minimize the probability of incorrectly classifying **fake images** (generated by the Generator) as real.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Key Steps**\n",
    "\n",
    "#### **Step 1: Zero Gradients**\n",
    "```python\n",
    "D.zero_grad()\n",
    "```\n",
    "- This clears the gradients of the Discriminator's parameters before the backward pass.\n",
    "- Ensures that accumulated gradients from previous iterations do not interfere with the current one.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Step 2: Train Discriminator on Real Data**\n",
    "```python\n",
    "x_real, y_real = x.view(-1, mnist_dim), torch.ones(bs, 1)\n",
    "x_real, y_real = Variable(x_real.to(device)), Variable(y_real.to(device))\n",
    "```\n",
    "- **`x_real`**:\n",
    "  - `x` is the batch of real MNIST images (from the dataset).\n",
    "  - `x.view(-1, mnist_dim)` flattens each 28x28 image into a 1D vector of size 784 (`mnist_dim`).\n",
    "- **`y_real`**:\n",
    "  - A tensor of size `(batch_size, 1)` filled with ones (indicating real images).\n",
    "- **Convert to `Variable` and move to `device`**:\n",
    "  - Ensures that data is compatible with GPU (if used) and supports gradient tracking.\n",
    "\n",
    "```python\n",
    "D_output = D(x_real)\n",
    "D_real_loss = criterion(D_output, y_real)\n",
    "D_real_score = D_output\n",
    "```\n",
    "- **`D_output`**:\n",
    "  - The Discriminator predicts a probability for each image being real.\n",
    "  - Output shape: `(batch_size, 1)`.\n",
    "- **`D_real_loss`**:\n",
    "  - Binary Cross-Entropy Loss between the predicted probabilities and the real label (`1`).\n",
    "  - Encourages the Discriminator to classify real images correctly.\n",
    "- **`D_real_score`**:\n",
    "  - The raw output of the Discriminator for real images, used for analysis.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Step 3: Train Discriminator on Fake Data**\n",
    "```python\n",
    "z = Variable(torch.randn(bs, z_dim).to(device))\n",
    "x_fake, y_fake = G(z), Variable(torch.zeros(bs, 1).to(device))\n",
    "```\n",
    "- **`z`**:\n",
    "  - A batch of random noise vectors sampled from a standard normal distribution.\n",
    "  - Shape: `(batch_size, z_dim)`.\n",
    "- **`x_fake`**:\n",
    "  - Fake images generated by the Generator from the noise vectors.\n",
    "  - Shape: `(batch_size, mnist_dim)` (same as real images).\n",
    "- **`y_fake`**:\n",
    "  - A tensor of size `(batch_size, 1)` filled with zeros (indicating fake images).\n",
    "\n",
    "```python\n",
    "D_output = D(x_fake)\n",
    "D_fake_loss = criterion(D_output, y_fake)\n",
    "D_fake_score = D_output\n",
    "```\n",
    "- **`D_output`**:\n",
    "  - The Discriminator predicts a probability for each fake image being real.\n",
    "  - Output shape: `(batch_size, 1)`.\n",
    "- **`D_fake_loss`**:\n",
    "  - Binary Cross-Entropy Loss between the predicted probabilities and the fake label (`0`).\n",
    "  - Encourages the Discriminator to classify fake images as fake.\n",
    "- **`D_fake_score`**:\n",
    "  - The raw output of the Discriminator for fake images, used for analysis.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Step 4: Compute Total Discriminator Loss**\n",
    "```python\n",
    "D_loss = D_real_loss + D_fake_loss\n",
    "```\n",
    "- The total Discriminator loss is the sum of:\n",
    "  - `D_real_loss`: Loss on real images.\n",
    "  - `D_fake_loss`: Loss on fake images.\n",
    "- This ensures the Discriminator learns from both real and fake samples.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Step 5: Backward Pass and Optimizer Step**\n",
    "```python\n",
    "D_loss.backward()\n",
    "D_optimizer.step()\n",
    "```\n",
    "- **`D_loss.backward()`**:\n",
    "  - Computes the gradients of the loss with respect to the Discriminator's parameters.\n",
    "- **`D_optimizer.step()`**:\n",
    "  - Updates the Discriminator's parameters based on the computed gradients.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Step 6: Return Discriminator Loss**\n",
    "```python\n",
    "return D_loss.data.item()\n",
    "```\n",
    "- Returns the total Discriminator loss as a scalar for logging or monitoring.\n",
    "\n",
    "---\n",
    "\n",
    "### **Summary**\n",
    "1. **Real Data**:\n",
    "   - The Discriminator learns to classify real images as real $( y = 1 )$\n",
    "   - Loss: $ \\mathcal{L}_{D_{\\text{real}}} = -\\log(D(x_{\\text{real}})) $\n",
    "2. **Fake Data**:\n",
    "   - The Discriminator learns to classify fake images as fake $( y = 0 )$\n",
    "   - Loss: $ \\mathcal{L}_{D_{\\text{fake}}} = -\\log(1 - D(x_{\\text{fake}})) $\n",
    "3. **Total Loss**:\n",
    "   - $ \\mathcal{L}_D = \\mathcal{L}_{D_{\\text{real}}} + \\mathcal{L}_{D_{\\text{fake}}} $\n",
    "4. **Optimization**:\n",
    "   - The Discriminator's parameters are updated to minimize $ \\mathcal{L}_D $\n",
    "\n",
    "---\n",
    "\n",
    "### **Flow Overview**\n",
    "1. Clear previous gradients: `D.zero_grad()`.\n",
    "2. Compute loss on real data (real images labeled as real).\n",
    "3. Compute loss on fake data (fake images labeled as fake).\n",
    "4. Sum up the losses.\n",
    "5. Backpropagate and update the Discriminator's weights.\n",
    "6. Return the loss for monitoring.\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Concepts**\n",
    "- The Discriminator's objective is to maximize accuracy for real vs. fake classification.\n",
    "- **Real Label = 1**, **Fake Label = 0**:\n",
    "  - Real images: Push $ D(x_{\\text{real}}) \\to 1 $\n",
    "  - Fake images: Push $ D(x_{\\text{fake}}) \\to 0 $\n",
    "- Gradients are computed only for the Discriminator in this step (Generator remains untouched)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def D_train(x):\n",
    "    #=======================Train the discriminator=======================#\n",
    "    D.zero_grad()\n",
    "\n",
    "    # train discriminator on real\n",
    "    x_real, y_real = x.view(-1, mnist_dim), torch.ones(bs, 1)\n",
    "    x_real, y_real = Variable(x_real.to(device)), Variable(y_real.to(device))\n",
    "\n",
    "    D_output = D(x_real)\n",
    "    D_real_loss = criterion(D_output, y_real)\n",
    "    D_real_score = D_output\n",
    "\n",
    "    # train discriminator on facke\n",
    "    z = Variable(torch.randn(bs, z_dim).to(device))\n",
    "    x_fake, y_fake = G(z), Variable(torch.zeros(bs, 1).to(device))\n",
    "\n",
    "    D_output = D(x_fake)\n",
    "    D_fake_loss = criterion(D_output, y_fake)\n",
    "    D_fake_score = D_output\n",
    "\n",
    "    # gradient backprop & optimize ONLY D's parameters\n",
    "    D_loss = D_real_loss + D_fake_loss\n",
    "    D_loss.backward()\n",
    "    D_optimizer.step()\n",
    "        \n",
    "    return  D_loss.data.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def G_train(x):\n",
    "    #=======================Train the generator=======================#\n",
    "    G.zero_grad()\n",
    "\n",
    "    z = Variable(torch.randn(bs, z_dim).to(device))\n",
    "    y = Variable(torch.ones(bs, 1).to(device))\n",
    "\n",
    "    G_output = G(z)\n",
    "    D_output = D(G_output)\n",
    "    G_loss = criterion(D_output, y)\n",
    "\n",
    "    # gradient backprop & optimize ONLY G's parameters\n",
    "    G_loss.backward()\n",
    "    G_optimizer.step()\n",
    "        \n",
    "    return G_loss.data.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/200]: loss_d: 0.999, loss_g: 2.759\n",
      "[2/200]: loss_d: 1.076, loss_g: 1.555\n",
      "[3/200]: loss_d: 0.892, loss_g: 1.973\n",
      "[4/200]: loss_d: 0.585, loss_g: 2.597\n",
      "[5/200]: loss_d: 0.583, loss_g: 2.475\n",
      "[6/200]: loss_d: 0.638, loss_g: 2.468\n",
      "[7/200]: loss_d: 0.595, loss_g: 2.396\n",
      "[8/200]: loss_d: 0.621, loss_g: 2.401\n",
      "[9/200]: loss_d: 0.582, loss_g: 2.597\n",
      "[10/200]: loss_d: 0.646, loss_g: 2.321\n",
      "[11/200]: loss_d: 0.709, loss_g: 2.203\n",
      "[12/200]: loss_d: 0.750, loss_g: 2.110\n",
      "[13/200]: loss_d: 0.742, loss_g: 2.058\n",
      "[14/200]: loss_d: 0.745, loss_g: 2.039\n",
      "[15/200]: loss_d: 0.762, loss_g: 1.979\n",
      "[16/200]: loss_d: 0.836, loss_g: 1.832\n",
      "[17/200]: loss_d: 0.798, loss_g: 1.896\n",
      "[18/200]: loss_d: 0.772, loss_g: 1.932\n",
      "[19/200]: loss_d: 0.837, loss_g: 1.768\n",
      "[20/200]: loss_d: 0.884, loss_g: 1.671\n",
      "[21/200]: loss_d: 0.884, loss_g: 1.673\n",
      "[22/200]: loss_d: 0.916, loss_g: 1.581\n",
      "[23/200]: loss_d: 0.907, loss_g: 1.576\n",
      "[24/200]: loss_d: 0.934, loss_g: 1.569\n",
      "[25/200]: loss_d: 0.908, loss_g: 1.610\n",
      "[26/200]: loss_d: 0.958, loss_g: 1.481\n",
      "[27/200]: loss_d: 0.984, loss_g: 1.432\n",
      "[28/200]: loss_d: 1.037, loss_g: 1.323\n",
      "[29/200]: loss_d: 1.013, loss_g: 1.374\n",
      "[30/200]: loss_d: 1.031, loss_g: 1.342\n",
      "[31/200]: loss_d: 1.031, loss_g: 1.325\n",
      "[32/200]: loss_d: 1.034, loss_g: 1.313\n",
      "[33/200]: loss_d: 1.049, loss_g: 1.303\n",
      "[34/200]: loss_d: 1.048, loss_g: 1.313\n",
      "[35/200]: loss_d: 1.040, loss_g: 1.328\n",
      "[36/200]: loss_d: 1.067, loss_g: 1.259\n",
      "[37/200]: loss_d: 1.076, loss_g: 1.234\n",
      "[38/200]: loss_d: 1.093, loss_g: 1.206\n",
      "[39/200]: loss_d: 1.097, loss_g: 1.204\n",
      "[40/200]: loss_d: 1.104, loss_g: 1.193\n",
      "[41/200]: loss_d: 1.115, loss_g: 1.181\n",
      "[42/200]: loss_d: 1.123, loss_g: 1.154\n",
      "[43/200]: loss_d: 1.126, loss_g: 1.152\n",
      "[44/200]: loss_d: 1.130, loss_g: 1.141\n",
      "[45/200]: loss_d: 1.149, loss_g: 1.103\n",
      "[46/200]: loss_d: 1.146, loss_g: 1.108\n",
      "[47/200]: loss_d: 1.146, loss_g: 1.117\n",
      "[48/200]: loss_d: 1.158, loss_g: 1.108\n",
      "[49/200]: loss_d: 1.161, loss_g: 1.112\n",
      "[50/200]: loss_d: 1.159, loss_g: 1.094\n",
      "[51/200]: loss_d: 1.164, loss_g: 1.083\n",
      "[52/200]: loss_d: 1.161, loss_g: 1.094\n",
      "[53/200]: loss_d: 1.171, loss_g: 1.075\n",
      "[54/200]: loss_d: 1.174, loss_g: 1.054\n",
      "[55/200]: loss_d: 1.190, loss_g: 1.040\n",
      "[56/200]: loss_d: 1.197, loss_g: 1.031\n",
      "[57/200]: loss_d: 1.190, loss_g: 1.037\n",
      "[58/200]: loss_d: 1.193, loss_g: 1.037\n",
      "[59/200]: loss_d: 1.198, loss_g: 1.030\n",
      "[60/200]: loss_d: 1.188, loss_g: 1.036\n",
      "[61/200]: loss_d: 1.202, loss_g: 1.020\n",
      "[62/200]: loss_d: 1.198, loss_g: 1.025\n",
      "[63/200]: loss_d: 1.206, loss_g: 1.015\n",
      "[64/200]: loss_d: 1.209, loss_g: 0.999\n",
      "[65/200]: loss_d: 1.208, loss_g: 1.010\n",
      "[66/200]: loss_d: 1.205, loss_g: 1.012\n",
      "[67/200]: loss_d: 1.212, loss_g: 1.000\n",
      "[68/200]: loss_d: 1.217, loss_g: 1.006\n",
      "[69/200]: loss_d: 1.230, loss_g: 0.972\n",
      "[70/200]: loss_d: 1.227, loss_g: 0.974\n",
      "[71/200]: loss_d: 1.215, loss_g: 1.005\n",
      "[72/200]: loss_d: 1.220, loss_g: 0.983\n"
     ]
    }
   ],
   "source": [
    "n_epoch = 200\n",
    "for epoch in range(1, n_epoch + 1):\n",
    "    D_losses, G_losses = [], []\n",
    "\n",
    "    for batch_idx, (x, _) in enumerate(train_loader):\n",
    "        # Train Discriminator and Generator\n",
    "        D_loss = D_train(x)\n",
    "        G_loss = G_train(x)\n",
    "\n",
    "        # Append the losses for this batch\n",
    "        D_losses.append(D_loss)\n",
    "        G_losses.append(G_loss)\n",
    "\n",
    "    # Calculate the mean losses for the epoch\n",
    "    avg_D_loss = sum(D_losses) / len(D_losses)\n",
    "    avg_G_loss = sum(G_losses) / len(G_losses)\n",
    "\n",
    "    # Print the epoch summary\n",
    "    print(f'[{epoch}/{n_epoch}]: loss_d: {avg_D_loss:.3f}, loss_g: {avg_G_loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    test_z = Variable(torch.randn(bs, z_dim).to(device))\n",
    "    generated = G(test_z)\n",
    "\n",
    "    save_image(generated.view(generated.size(0), 1, 28, 28), './samples/sample_' + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchgpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
